{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOl7uRD9wMPyfJPlNrlDM7z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PedroDev-coder/ProjetoFinalRegressao/blob/main/Projeto_Final_Parte2_Regressao.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Regressão"
      ],
      "metadata": {
        "id": "lw4Ez8AkdxNU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Carregar a base de dados - 'mpg' seaborn"
      ],
      "metadata": {
        "id": "o3XRSTPid1oM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 292,
      "metadata": {
        "id": "7O2aZzbiQ4Hq"
      },
      "outputs": [],
      "source": [
        "from seaborn import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/mpg.csv\"\n",
        "\n",
        "#dataset = load_dataset('mpg') #Carrega o dataset\n",
        "\n",
        "dataset = pd.read_csv(url)\n",
        "\n",
        "dataset #Mostra o dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Detalhes do dataset\n",
        "\n",
        "dataset.describe()"
      ],
      "metadata": {
        "id": "0vaXI3hVRq-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tratamento"
      ],
      "metadata": {
        "id": "q0L3CJblTTw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Retira as linhas que contém \"NaN\"\n",
        "\n",
        "dataset = dataset.dropna()\n",
        "\n",
        "dataset #dataset filtrado (tratado)"
      ],
      "metadata": {
        "id": "O8IxQvEuRtax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Separe os dados em 2 variáveis diferentes\n",
        "\n",
        "Y = dataset['mpg'] #label (target)\n",
        "\n",
        "column = ['mpg']\n",
        "\n",
        "Y = pd.DataFrame(data = Y, columns = column)\n",
        "\n",
        "X = dataset.drop(['mpg','name'] , axis = 1) #features (data)\n",
        "\n",
        "Tabela = dataset.drop(['name'] , axis = 1) #Dados para gerar os gráficos"
      ],
      "metadata": {
        "id": "Mzrkt41Knlgs"
      },
      "execution_count": 295,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y.shape) #(392,1)\n",
        "print(X.shape) #(392, 7)"
      ],
      "metadata": {
        "id": "KoYzEKi5o_dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y #Mostra o target"
      ],
      "metadata": {
        "id": "0Gtc_HncpgOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X #Mostra as features"
      ],
      "metadata": {
        "id": "hcysiQnxn-nV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import make_column_transformer\n",
        "\n",
        "column_transformer = make_column_transformer((OneHotEncoder(), ['origin']), remainder='passthrough')\n",
        "\n",
        "X = column_transformer.fit_transform(X)\n",
        "\n",
        "columns_names = ['origin_europe', 'origin_japan', 'origin_usa', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year']\n",
        "\n",
        "#columns_names = column_transformer.get_feature_names_out()\n",
        "\n",
        "X = pd.DataFrame(data = X, columns = columns_names)\n",
        "\n",
        "X #Mostra os valores das features"
      ],
      "metadata": {
        "id": "_bmoCibOpL86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Normalização"
      ],
      "metadata": {
        "id": "ndb82uxcS3D5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "# Normalizando todo X\n",
        "\n",
        "X['cylinders'] = MinMaxScaler().fit_transform(np.array(dataset['cylinders']).reshape(-1,1))\n",
        "X['displacement'] = MinMaxScaler().fit_transform(np.array(dataset['displacement']).reshape(-1,1))\n",
        "X['horsepower'] = MinMaxScaler().fit_transform(np.array(dataset['horsepower']).reshape(-1,1))\n",
        "X['weight'] = MinMaxScaler().fit_transform(np.array(dataset['weight']).reshape(-1,1))\n",
        "X['acceleration'] = MinMaxScaler().fit_transform(np.array(dataset['acceleration']).reshape(-1,1))\n",
        "X['model_year'] = MinMaxScaler().fit_transform(np.array(dataset['model_year']).reshape(-1,1))\n",
        "\n",
        "# Outra Forma de Normalizar\n",
        "\n",
        "#df = X.values\n",
        "#min_max_scaler = preprocessing.MinMaxScaler()\n",
        "#x_scaled = min_max_scaler.fit_transform(df)\n",
        "#X = pd.DataFrame(x_scaled)"
      ],
      "metadata": {
        "id": "UgQ9i4g0sPx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X #Mostra os valores das features normalizadas"
      ],
      "metadata": {
        "id": "6MrTcEmItO1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Treinamento"
      ],
      "metadata": {
        "id": "-XLm5SRPdmBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "\n",
        "show1_MSE = [] #Decision tree 1 MSE\n",
        "show1_RMSE = [] #Decision tree 1 RMSE\n",
        "show1_MAE = [] #Decision tree 1 MAE\n",
        "\n",
        "show2_MSE = [] #Decision tree 2 MSE\n",
        "show2_RMSE = [] #Decision tree 2 RMSE\n",
        "show2_MAE = [] #Decision tree 2 MAE\n",
        "\n",
        "show3_MSE = [] #K-nearest neighbors 1 MSE\n",
        "show3_RMSE = [] #K-nearest neighbors 1 RMSE\n",
        "show3_MAE = [] #K-nearest neighbors 1 MAE\n",
        "\n",
        "show4_MSE = [] #K-nearest neighbors 2 MSE\n",
        "show4_RMSE = [] #K-nearest neighbors 2 RMSE\n",
        "show4_MAE = [] #K-nearest neighbors 2 MAE\n",
        "\n",
        "show5_MSE = [] #MLP\n",
        "show5_RMSE = [] #MLP\n",
        "show5_MAE = [] #MLP\n",
        "\n",
        "show6_MSE = [] #MLP\n",
        "show6_RMSE = [] #MLP\n",
        "show6_MAE = [] #MLP\n",
        "\n",
        "show7_MSE = [] #SVM\n",
        "show7_RMSE = [] #SVM\n",
        "show7_MAE = [] #SVM\n",
        "\n",
        "show8_MSE = [] #SVM\n",
        "show8_RMSE = [] #SVM\n",
        "show8_MAE = [] #SVM\n",
        "\n",
        "show9_MSE = [] #Random Forest\n",
        "show9_RMSE = [] #Random Forest\n",
        "show9_MAE = [] #Random Forest\n",
        "\n",
        "show10_MSE = [] #GradienteBoosting\n",
        "show10_RMSE = [] #GradienteBoosting\n",
        "show10_MAE = [] #GradienteBoosting\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "\n",
        "  res = train_test_split(X, Y, train_size=0.8, test_size=0.2, random_state=None)\n",
        "  train_data, test_data, train_labels, test_labels = res # 80% treino e 20% teste\n",
        "\n",
        "\n",
        "  # DecisionTree's\n",
        "\n",
        "  model1 = DecisionTreeRegressor()\n",
        "  model2 = DecisionTreeRegressor()\n",
        "\n",
        "  model1 = model1.fit(train_data, train_labels)\n",
        "  model2 = model2.fit(train_data, train_labels)\n",
        "\n",
        "  result1 = model1.predict(test_data)\n",
        "  result2 = model2.predict(test_data)\n",
        "\n",
        "  MSE1 = metrics.mean_squared_error(test_labels, result1)\n",
        "  MSE2 = metrics.mean_squared_error(test_labels, result2)\n",
        "\n",
        "  RMSE1 = np.sqrt(MSE1)\n",
        "  RMSE2 = np.sqrt(MSE2)\n",
        "\n",
        "  MAE1 = metrics.mean_absolute_error(test_labels, result1)\n",
        "  MAE2 = metrics.mean_absolute_error(test_labels, result2)\n",
        "\n",
        "  show1_MSE.append(MSE1)\n",
        "  show2_MSE.append(MSE2)\n",
        "\n",
        "  show1_RMSE.append(RMSE1)\n",
        "  show2_RMSE.append(RMSE2)\n",
        "\n",
        "  show1_MAE.append(MAE1)\n",
        "  show2_MAE.append(MAE2)\n",
        "\n",
        "  # KNeighbors\n",
        "\n",
        "  model3 = KNeighborsRegressor(n_neighbors=3, metric='euclidean', algorithm='brute')\n",
        "  model4 = KNeighborsRegressor(n_neighbors=5, metric='minkowski', algorithm='auto')\n",
        "\n",
        "  model3 = model3.fit(train_data, train_labels)\n",
        "  model4 = model4.fit(train_data, train_labels)\n",
        "\n",
        "  result3 = model3.predict(test_data)\n",
        "  result4 = model4.predict(test_data)\n",
        "\n",
        "  MSE3 = metrics.mean_squared_error(test_labels, result3)\n",
        "  MSE4 = metrics.mean_squared_error(test_labels, result4)\n",
        "\n",
        "  RMSE3 = np.sqrt(MSE3)\n",
        "  RMSE4 = np.sqrt(MSE4)\n",
        "\n",
        "  MAE3 = metrics.mean_absolute_error(test_labels, result3)\n",
        "  MAE4 = metrics.mean_absolute_error(test_labels, result4)\n",
        "\n",
        "  show3_MSE.append(MSE3)\n",
        "  show4_MSE.append(MSE4)\n",
        "\n",
        "  show3_RMSE.append(RMSE3)\n",
        "  show4_RMSE.append(RMSE4)\n",
        "\n",
        "  show3_MAE.append(MAE3)\n",
        "  show4_MAE.append(MAE4)\n",
        "\n",
        "  # MLP's\n",
        "\n",
        "  model5 = MLPRegressor(hidden_layer_sizes=(15,10), activation='tanh',max_iter=5000)\n",
        "  model6 = MLPRegressor(hidden_layer_sizes=(5,5), activation='relu',max_iter=5000)\n",
        "\n",
        "  model5 = model5.fit(train_data, train_labels)\n",
        "  model6 = model6.fit(train_data, train_labels)\n",
        "\n",
        "  result5 = model5.predict(test_data)\n",
        "  result6 = model6.predict(test_data)\n",
        "\n",
        "  MSE5 = metrics.mean_squared_error(test_labels, result5)\n",
        "  MSE6 = metrics.mean_squared_error(test_labels, result6)\n",
        "\n",
        "  RMSE5 = np.sqrt(MSE5)\n",
        "  RMSE6 = np.sqrt(MSE6)\n",
        "\n",
        "  MAE5 = metrics.mean_absolute_error(test_labels, result5)\n",
        "  MAE6 = metrics.mean_absolute_error(test_labels, result6)\n",
        "\n",
        "  show5_MSE.append(MSE5)\n",
        "  show6_MSE.append(MSE6)\n",
        "\n",
        "  show5_RMSE.append(RMSE5)\n",
        "  show6_RMSE.append(RMSE6)\n",
        "\n",
        "  show5_MAE.append(MAE5)\n",
        "  show6_MAE.append(MAE6)\n",
        "\n",
        "  #SVM's\n",
        "\n",
        "  model7 = SVR(C= 1.0, kernel= 'rbf', gamma= 'scale')\n",
        "  model8 = SVR(C= 1.0, kernel= 'poly', gamma= 'auto')\n",
        "\n",
        "  model7 = model7.fit(train_data, train_labels)\n",
        "  model8 = model8.fit(train_data, train_labels)\n",
        "\n",
        "  result7 = model7.predict(test_data)\n",
        "  result8 = model8.predict(test_data)\n",
        "\n",
        "  MSE7 = metrics.mean_squared_error(test_labels, result7)\n",
        "  MSE8 = metrics.mean_squared_error(test_labels, result8)\n",
        "\n",
        "  RMSE7 = np.sqrt(MSE7)\n",
        "  RMSE8 = np.sqrt(MSE8)\n",
        "\n",
        "  MAE7 = metrics.mean_absolute_error(test_labels, result7)\n",
        "  MAE8 = metrics.mean_absolute_error(test_labels, result8)\n",
        "\n",
        "  show7_MSE.append(MSE7)\n",
        "  show8_MSE.append(MSE8)\n",
        "\n",
        "  show7_RMSE.append(RMSE7)\n",
        "  show8_RMSE.append(RMSE8)\n",
        "\n",
        "  show7_MAE.append(MAE7)\n",
        "  show8_MAE.append(MAE8)\n",
        "\n",
        "\n",
        "  #Random Forest\n",
        "\n",
        "  model9 = RandomForestRegressor(n_estimators=100, criterion='gini', max_depth=None)\n",
        "  model9.fit(train_data, train_labels)\n",
        "  result9 = model9.predict(test_data)\n",
        "\n",
        "  MSE9 = metrics.mean_squared_error(test_labels, result9)\n",
        "  RMSE9 = np.sqrt(MSE9) # or mse**(0.5)\n",
        "  MAE9 = metrics.mean_absolute_error(test_labels, result9)\n",
        "\n",
        "  show9_MSE.append(MSE9)\n",
        "  show9_RMSE.append(RMSE9)\n",
        "  show9_MAE.append(MAE9)\n",
        "\n",
        "  #Gradient Boosting\n",
        "\n",
        "  model10 = GradientBoostingRegressor()\n",
        "  model10.fit(train_data, train_labels)\n",
        "  result10 = model10.predict(test_data)\n",
        "\n",
        "  MSE10 = metrics.mean_squared_error(test_labels, result10)\n",
        "  RMSE10 = np.sqrt(MSE10)\n",
        "  MAE10 = metrics.mean_absolute_error(test_labels, result10)\n",
        "\n",
        "  show10_MSE.append(MSE10)\n",
        "  show10_RMSE.append(RMSE10)\n",
        "  show10_MAE.append(MAE10)"
      ],
      "metadata": {
        "id": "8P_otidGqC46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Gráficos"
      ],
      "metadata": {
        "id": "mJDdtus6vJON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns # API de visualização\n",
        "\n",
        "train_dataset = Tabela.sample(frac=0.8,random_state=0)\n",
        "\n",
        "sns.pairplot(train_dataset[['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration']], diag_kind=\"kde\", hue= 'mpg')"
      ],
      "metadata": {
        "id": "TJtImLx4hnNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.regplot(data = Tabela, x=\"weight\", y=\"mpg\")"
      ],
      "metadata": {
        "id": "SPsY6-aDuCD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(x = \"cylinders\", y = \"mpg\", data = Tabela, hue = \"origin\")"
      ],
      "metadata": {
        "id": "AzGCZ7-svU27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Resultados"
      ],
      "metadata": {
        "id": "6NIV0KWndp3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resultados\n",
        "\n",
        "print(\"========== TREEs ==========\")\n",
        "\n",
        "media1 = sum(show1_MSE) / len(show1_MSE)\n",
        "print(\"\\nTree1 MSE {:.3f}\".format(media1))\n",
        "media2 = sum(show2_MSE) / len(show2_MSE)\n",
        "print(\"Tree2 MSE {:.3f}\".format(media2))\n",
        "media1 = sum(show1_RMSE) / len(show1_RMSE)\n",
        "print(\"\\nTree1 RMSE {:.3f}\".format(media1))\n",
        "media2 = sum(show2_RMSE) / len(show2_RMSE)\n",
        "print(\"Tree2 RMSE {:.3f}\".format(media2))\n",
        "media1 = sum(show1_MAE) / len(show1_MAE)\n",
        "print(\"\\nTree1 MAE {:.3f}\".format(media1))\n",
        "media2 = sum(show2_MAE) / len(show2_MAE)\n",
        "print(\"Tree2 MAE {:.3f}\\n\".format(media2))\n",
        "\n",
        "print(\"========== KNNs ===========\")\n",
        "\n",
        "media3 = sum(show3_MSE) / len(show3_MSE)\n",
        "print(\"\\nKNN euclidean MSE {:.3f}\".format(media3))\n",
        "media4 = sum(show4_MSE) / len(show4_MSE)\n",
        "print(\"KNN minkowski MSE {:.3f}\".format(media4))\n",
        "media3 = sum(show3_RMSE) / len(show3_RMSE)\n",
        "print(\"\\nKNN euclidean RMSE {:.3f}\".format(media3))\n",
        "media4 = sum(show4_RMSE) / len(show4_RMSE)\n",
        "print(\"KNN minkowski RMSE {:.3f}\".format(media4))\n",
        "media3 = sum(show3_MAE) / len(show3_MAE)\n",
        "print(\"\\nKNN euclidean MAE {:.3f}\".format(media3))\n",
        "media4 = sum(show4_MAE) / len(show4_MAE)\n",
        "print(\"KNN minkowski MAE {:.3f}\\n\".format(media4))\n",
        "\n",
        "print(\"========== MLPs ===========\")\n",
        "\n",
        "media5 = sum(show5_MSE) / len(show5_MSE)\n",
        "print(\"\\nMLP1 tanh MSE {:.3f}\".format(media5))\n",
        "media6 = sum(show6_MSE) / len(show6_MSE)\n",
        "print(\"MLP2 relu MSE {:.3f}\".format(media6))\n",
        "media5 = sum(show5_RMSE) / len(show5_RMSE)\n",
        "print(\"\\nMLP1 tanh RMSE {:.3f}\".format(media5))\n",
        "media6 = sum(show6_RMSE) / len(show6_RMSE)\n",
        "print(\"MLP2 relu RMSE {:.3f}\".format(media6))\n",
        "media5 = sum(show5_MAE) / len(show5_MAE)\n",
        "print(\"\\nMLP1 tanh MAE {:.3f}\".format(media5))\n",
        "media6 = sum(show6_MAE) / len(show6_MAE)\n",
        "print(\"MLP2 relu MAE {:.3f}\\n\".format(media6))\n",
        "\n",
        "print(\"========== SVRs ===========\")\n",
        "\n",
        "media7 = sum(show7_MSE) / len(show7_MSE)\n",
        "print(\"\\nSVR1 MSE {:.3f}\".format(media7))\n",
        "media8 = sum(show8_MSE) / len(show8_MSE)\n",
        "print(\"SVR2 MSE {:.3f}\".format(media8))\n",
        "media7 = sum(show7_RMSE) / len(show7_RMSE)\n",
        "print(\"\\nSVR1 RMSE {:.3f}\".format(media7))\n",
        "media8 = sum(show8_RMSE) / len(show8_RMSE)\n",
        "print(\"SVR2 RMSE {:.3f}\".format(media8))\n",
        "media7 = sum(show7_MAE) / len(show7_MAE)\n",
        "print(\"\\nSVR1 MAE {:.3f}\".format(media7))\n",
        "media8 = sum(show8_MAE) / len(show8_MAE)\n",
        "print(\"SVR2 MAE {:.3f}\\n\".format(media8))\n",
        "\n",
        "print(\"====== RandomForest =======\")\n",
        "\n",
        "media9 = sum(show9_MSE) / len(show9_MSE)\n",
        "print(\"\\nRandomForest MSE: {:.3f}\".format(media9))\n",
        "media9 = sum(show9_RMSE) / len(show9_RMSE)\n",
        "print(\"RandomForest RMSE: {:.3f}\".format(media9))\n",
        "media9 = sum(show9_MAE) / len(show9_MAE)\n",
        "print(\"RandomForest MAE: {:.3f}\\n\".format(media9))\n",
        "\n",
        "print(\"===== GradientBoosting ======\")\n",
        "\n",
        "media10 = sum(show10_MSE) / len(show10_MSE)\n",
        "print(\"\\nGradientBoosting MSE: {:.3f}\".format(media10))\n",
        "media10 = sum(show10_RMSE) / len(show10_RMSE)\n",
        "print(\"GradientBoosting RMSE: {:.3f}\".format(media10))\n",
        "media10 = sum(show10_MAE) / len(show10_MAE)\n",
        "print(\"GradientBoosting MAE: {:.3f}\\n\".format(media10))\n",
        "\n",
        "#print(list(show1_MSE))\n",
        "#print(list(show1_RMSE))\n",
        "#print(list(show1_MAE))"
      ],
      "metadata": {
        "id": "vjCZWmF0689t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}